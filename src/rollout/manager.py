"""
Rollout Manager - è´Ÿè´£è½¨è¿¹ç”Ÿæˆ
ä½¿ç”¨å¯æ’æ‹”çš„æ¨ç†å¼•æ“æ¶æ„
"""
from typing import List, Dict, Any
from transformers import AutoTokenizer


class RolloutManager:
    """
    Rollout ç®¡ç†å™¨ - ç”Ÿæˆè®­ç»ƒè½¨è¿¹
    
    æ ¸å¿ƒè®¾è®¡:
    1. Rollout æ—¶ç›´æ¥è®°å½• token IDs (ä¸æ˜¯æ–‡æœ¬)
    2. æ ¹æ®æ¥æºæ ‡è®° loss-mask:
       - User â†’ 0 (ä¸è®­ç»ƒ)
       - Assistant â†’ 1 (è®­ç»ƒ)
       - Tool â†’ 0 (ä¸è®­ç»ƒ)
    3. æ”¯æŒå¯æ’æ‹”çš„æ¨ç†å¼•æ“ (HF / SGLang / ...)
    """
    
    def __init__(
        self,
        model_path: str,
        agent,  # BaseAgent
        tokenizer: AutoTokenizer,
        inference_engine=None  # å¯é€‰çš„æ¨ç†å¼•æ“
    ):
        self.model_path = model_path
        self.agent = agent
        self.tokenizer = tokenizer
        
        # æ¨ç†å¼•æ“ (é»˜è®¤ä½¿ç”¨ HF)
        if inference_engine is None:
            from .hf_engine import HFInferenceEngine
            self.engine = HFInferenceEngine(model_path)
        else:
            self.engine = inference_engine
        
        self.started = False
    
    def start(self):
        """å¯åŠ¨ Rollout ç¯å¢ƒ"""
        if not self.started:
            self.engine.load()
            self.started = True
    
    def _tokenize_user_message(self, content: str) -> List[int]:
        """Tokenize user æ¶ˆæ¯"""
        message = {"role": "user", "content": content}
        tokens = self.tokenizer.apply_chat_template(
            [message],
            tokenize=True,
            add_generation_prompt=True
        )
        return tokens
    
    def _tokenize_tool_output(self, content: str) -> List[int]:
        """Tokenize tool è¾“å‡º"""
        # ç®€å•å®ç°: ç›´æ¥ encode
        tokens = self.tokenizer.encode(
            f"\nTool Result: {content}\n\nAssistant: ",
            add_special_tokens=False
        )
        return tokens
    
    
    def generate_trajectory(
        self,
        prompt: str,
        ground_truth: Any,
        max_turns: int = 10,
        max_new_tokens: int = 256  # é™ä½é»˜è®¤å€¼ï¼ŒåŠ å¿«æ¨ç†
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆä¸€æ¡è½¨è¿¹
        
        Returns:
            {
                "tokens": List[int],
                "loss_mask": List[int],
                "reward": float,
                "response_length": int,
                "messages": List[Dict],
            }
        """
        # åˆå§‹åŒ–
        all_token_ids = []
        all_loss_mask = []
        messages = []
        
        # Turn 1: User prompt
        user_tokens = self._tokenize_user_message(prompt)
        all_token_ids.extend(user_tokens)
        all_loss_mask.extend([0] * len(user_tokens))
        messages.append({"role": "user", "content": prompt})
        
        # å¤šè½®ç”Ÿæˆ
        for turn in range(max_turns):
            prev_length = len(all_token_ids)
            
            # æ¨ç†å¼•æ“ç”Ÿæˆ
            full_tokens = self.engine.generate_tokens(
                all_token_ids,
                max_new_tokens=max_new_tokens
            )
            
            # è®¡ç®—å¢é‡ (Assistant çš„è¾“å‡º)
            assistant_tokens = full_tokens[prev_length:]
            
            # æ›´æ–° token åºåˆ—å’Œ mask
            all_token_ids.extend(assistant_tokens)
            all_loss_mask.extend([1] * len(assistant_tokens))  # è®­ç»ƒ!
            
            # è§£ç ç”¨äº Agent å¤„ç†
            assistant_text = self.tokenizer.decode(
                assistant_tokens,
                skip_special_tokens=True
            )
            messages.append({"role": "assistant", "content": assistant_text})
            
            # Agent å¤„ç†
            result = self.agent.process_turn(prompt, assistant_text, messages)
            
            if result.get("done", False):
                break
            
            # Tool è¾“å‡º (å¦‚æœæœ‰)
            if "tool_result" in result:
                tool_text = result["tool_result"]
                tool_tokens = self._tokenize_tool_output(tool_text)
                
                all_token_ids.extend(tool_tokens)
                all_loss_mask.extend([0] * len(tool_tokens))  # ä¸è®­ç»ƒ!
                
                messages.append({"role": "tool", "content": tool_text})
        
        # è®¡ç®— reward
        reward = self._compute_reward(messages, ground_truth)
        
        return {
            "tokens": all_token_ids,
            "loss_mask": all_loss_mask,
            "reward": reward,
            "response_length": len(all_token_ids),
            "messages": messages,
        }
    
    def _compute_reward(
        self,
        messages: List[Dict],
        ground_truth: Any
    ) -> float:
        """è®¡ç®— reward"""
        # æå–æœ€åä¸€ä¸ª assistant çš„å›å¤
        final_answer = None
        for msg in reversed(messages):
            if msg["role"] == "assistant":
                final_answer = msg["content"]
                break
        
        if final_answer is None:
            return 0.0
        
        # ç®€å•çš„åŒ¹é…æ£€æŸ¥
        if str(ground_truth) in final_answer:
            return 1.0
        else:
            return 0.0
    
    
    def generate_trajectories(
        self,
        dataset: List[Dict],
        samples_per_prompt: int = 4,
        max_new_tokens: int = 256  # æ–°å¢å‚æ•°
    ) -> List[Dict]:
        """
        æ‰¹é‡ç”Ÿæˆè½¨è¿¹ (GRPO é£æ ¼)
        
        Args:
            dataset: æ•°æ®é›†
            samples_per_prompt: æ¯ä¸ª prompt é‡‡æ ·å¤šå°‘æ¡è½¨è¿¹
            max_new_tokens: æ¯æ¬¡ç”Ÿæˆçš„æœ€å¤§ token æ•°
        
        Returns:
            è½¨è¿¹åˆ—è¡¨ï¼ŒåŒ…å« group_id ç”¨äºè®¡ç®— group-relative advantage
        """
        trajectories = []
        
        for group_id, item in enumerate(dataset):
            print(f"\nğŸ“ Prompt {group_id+1}/{len(dataset)}: {item['prompt'][:50]}...")
            
            # å¯¹åŒä¸€ä¸ª prompt é‡‡æ ·å¤šæ¬¡
            for sample_id in range(samples_per_prompt):
                print(f"  é‡‡æ · {sample_id+1}/{samples_per_prompt}...", end=" ")
                
                traj = self.generate_trajectory(
                    item["prompt"],
                    item["ground_truth"],
                    max_new_tokens=max_new_tokens  # ä¼ é€’å‚æ•°
                )
                
                # æ·»åŠ  group_id ç”¨äºè®¡ç®— group-relative advantage
                traj["group_id"] = group_id
                traj["sample_id"] = sample_id
                
                trajectories.append(traj)
                
                print(f"Reward: {traj['reward']:.2f}, Length: {traj['response_length']}")
        
        return trajectories
    
    def shutdown(self):
        """å…³é—­ Rollout ç¯å¢ƒ"""
        if self.started:
            self.engine.unload()
            self.started = False
    
    def __enter__(self):
        self.start()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.shutdown()
